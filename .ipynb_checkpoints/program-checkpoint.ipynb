{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Dodajemy importy",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.compose import make_column_selector, ColumnTransformer\nfrom sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom xgboost import XGBClassifier",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Wczytanie danych z separatorem \",\"",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(\"./loan_data.csv\", sep=\",\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Wyświetlenie danych",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Wyświetalnie dodatkowych informacji",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(df.info())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.set_option(\"display.max_columns\",None)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Zmieniamy typ na int gdyż nie potrzebujemy floatow",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df[\"person_age\"] = df[\"person_age\"].astype(int)\ndf[\"cb_person_cred_hist_length\"] = df[\"cb_person_cred_hist_length\"].astype(int)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "before_length = len(df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Wyswietlamy unikalne wartosci dla każdej kolumny",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "for column in df.columns:\n    print(column + \": \", df[column].unique())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Sprawdzamy czy nie ma takich rekordów, którzy więcej pracowali lub mieli dłuższą historie kredytową niż ich długość życia",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "found = False\nfor index, row in df.iterrows():\n    if row[\"person_age\"] < row[\"person_emp_exp\"]:\n        found = True\n        break\n    if row[\"person_age\"] < row[\"cb_person_cred_hist_length\"]:\n        found = True\n        break\nif found:\n    print(\"Są takie obserwacje, których czas pracy lub dlugość historii kredytowej jest większa niż długość życia\")\nelse:\n    print(\"Nie ma obserwacji, których czas pracy lub dlugość historii kredytowej jest większa niż długość życia\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Sprawdzamy czy są duplikaty",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"Ilość duplikatów - \", len(df[df.duplicated()]))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Usuwamy obserwacje gdzie wiek jest powyżej 100 lat",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = df[df[\"person_age\"] <= 100]\nprint(\"Usunięto \", before_length - len(df), \" wyników, gdzie wiek większy niż 100\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Służy nam do wyznaczenia podstawowych statystyk",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(df.describe())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Sprawdzamy jakiej częsci osób został udzielony kredyt",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(df[\"loan_status\"].value_counts(normalize = True))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Sprawdzmy czy są jakieś zależności, między zmiennymi",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(pd.crosstab(df[\"loan_status\"], df[\"person_gender\"], normalize=\"columns\"))\nprint(pd.crosstab(df[\"loan_status\"], df[\"person_education\"], normalize=\"columns\"))\nprint(pd.crosstab(df[\"loan_status\"], df[\"previous_loan_defaults_on_file\"], normalize = \"columns\"))\n\nplt.figure(figsize=(15, 6))\nsns.countplot(x='person_home_ownership', hue='loan_status', data=df)\nplt.title('Własność a status pożyczki')\nplt.xlabel('Własność')\nplt.ylabel('Liczba osób')\nplt.show()\n\nplt.figure(figsize=(15, 6))\nsns.countplot(x='loan_intent', hue='loan_status', data=df)\nplt.title('Cel pożyczki a status pożyczki')\nplt.xlabel('Cel Pożyczki')\nplt.ylabel('Liczba osób')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Obliczamy korelacje",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"Korelacja: \", (df[\"loan_amnt\"] * 100 / df[\"person_income\"]).corr(df[\"loan_percent_income\"]))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Sprawdzamy zależności między zmiennymi liczbowymi",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(10,7))\nsns.set_theme(font_scale = 1.3)\nsns.heatmap(df.select_dtypes(include=\"number\").corr()[\"loan_status\"].to_frame(), cbar = True, annot = True, square = True, cmap = \"Blues\")\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Odrzucamy możliwe nieznaczące zmienne",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = df.drop([\"person_gender\", \"person_education\", \"loan_percent_income\", \"person_age\", \"person_emp_exp\", \"cb_person_cred_hist_length\", \"credit_score\"], axis=1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Wyciągamy predytkory oraz zmienne celu",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "y = df[\"loan_status\"]\nX = df.drop([\"loan_status\"], axis=1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Dzielimy na zbiór uczący i testowy",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 313128)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Dzielimy zmienne na numeryczne i kategoryczne",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sel_num = make_column_selector(dtype_include=[\"int64\", \"float64\"])\nsel_cat = make_column_selector(dtype_include=\"object\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Sieci neurnowe\nZmienne numeryczne normalizujemy, a z katogrycznymi dzielimy na osobne kolumny dla kazdej wartości",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "preprocessor = ColumnTransformer(transformers =\n                                [(\"num\", MinMaxScaler(feature_range = (0, 1)), sel_num),\n                                 (\"cat\", OneHotEncoder(handle_unknown = \"ignore\"), sel_cat)])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Tworzymy potok, który na początku wykona preprocessor, który utworzyliśmy wyżej a potem juz klasyfikator oparty o sieci neuronowe, parametry zostały dobrane dzięki grid search",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pipeline = Pipeline(steps = [(\"prep\", preprocessor),\n                        (\"siec\", MLPClassifier(random_state=313128, max_iter=1000, hidden_layer_sizes=(50, 50)))])\npipeline.fit(X_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Uzyskujemy trafność modelu",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"Trafność: \")\nprint(\"Zbiór uczący: \", pipeline.score(X_train, y_train))\nprint(\"Zbiór testowy: \", pipeline.score(X_test, y_test))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Uzyskujemy macierze pomylek dla uczącej i testowej",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "y_train_pred = pipeline.predict(X_train)\ny_test_pred = pipeline.predict(X_test)\nconfusion_matrix_train = confusion_matrix(y_train, y_train_pred)\nconfusion_matrix_test = confusion_matrix(y_test, y_test_pred)\nprint(\"Macierze pomyłek: \")\nprint(\"Zbiór uczący: \")\nprint(pd.DataFrame(confusion_matrix_test))\nprint(\"Zbiór testowy: \")\nprint(pd.DataFrame(confusion_matrix_train))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Wyznaczamy tp, tn, fp, fn",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "tn_train, fp_train, fn_train, tp_train = confusion_matrix_train.ravel()\ntn_test, fp_test, fn_test, tp_test = confusion_matrix_test.ravel()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "uzyskujemy czułość modelu",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sensitivity_train = tp_train/(tp_train + fn_train)\nsensitivity_test = tp_test/(tp_test + fn_test)\nprint(\"Czułość: \")\nprint(\"Zbiór uczący: \", sensitivity_train)\nprint(\"Zbiór testowy: \", sensitivity_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Uzyskujemy swoistość modelu",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"Swoistość: \")\nprint(\"Zbiór uczący: \", tn_train/(tn_train + fp_train))\nprint(\"Zbiór testowy: \", tn_test/(tn_test + fp_test))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Uzyskujemy precyzje modelu",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "precision_train = tp_train/(tp_train + fp_train)\nprecision_test = tp_test/(tp_test + fp_test)\nprint(\"Precyzja: \")\nprint(\"Zbiór uczący: \", precision_train)\nprint(\"Zbiór testowy: \", precision_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Uzyskujemy f1 modelu",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"F1: \")\nprint(\"Zbiór uczący: \", 2*sensitivity_train*precision_train/(sensitivity_train + precision_train))\nprint(\"Zbiór testowy: \", 2*sensitivity_test*precision_test/(sensitivity_test + precision_test))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Uzyskujemy krzywą roc wraz z auc dla zbioru uczącego",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "y_train_prob = pipeline.predict_proba(X_train)[:, 1]\nfpr, tpr, thresholds = roc_curve(y_train, y_train_prob, pos_label = 1)\nauc = roc_auc_score(y_train, y_train_prob)\nplt.figure(figsize=(8,8))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='AUC = %0.2f' % auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('1 - specyficzność')\nplt.ylabel('Czułość')\nplt.title('Krzywa ROC - zbiór uczący')\nplt.legend(loc=\"lower right\")\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Uzyskujemy krzywą roc wraz z auc dla zbioru testowego",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "y_test_prob = pipeline.predict_proba(X_test)[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, y_test_prob, pos_label = 1)\nauc = roc_auc_score(y_test, y_test_prob)\nplt.figure(figsize=(8,8))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='AUC = %0.2f' % auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('1 - specyficzność')\nplt.ylabel('Czułość')\nplt.title('Krzywa ROC - zbiór testowy')\nplt.legend(loc=\"lower right\")\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# XGBOOST\nZmienne katogryczne dzielimy na osobne kolumny dla kazdej wartości",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "preprocessor = ColumnTransformer(transformers =\n                                [('num', 'passthrough', sel_num),\n                                 (\"cat\", OneHotEncoder(handle_unknown = \"ignore\"), sel_cat)])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Tworzymy potok, który na początku wykona preprocessor, który utworzyliśmy wyżej a potem juz klasyfikator oparty o xgboost, parametry zostały dobrane dzięki grid search",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pipeline = Pipeline(steps = [(\"prep\", preprocessor),\n                      (\"las\", XGBClassifier(objective='binary:logistic', gamma=1,  max_depth=7, n_estimators=500, subsample=0.8, learning_rate=0.1, random_state=313128))])\npipeline.fit(X_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Uzyskujemy trafność modelu",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"Trafność: \")\nprint(\"Zbiór uczący: \", pipeline.score(X_train, y_train))\nprint(\"Zbiór testowy: \", pipeline.score(X_test, y_test))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Uzyskujemy macierze pomylek dla uczącej i testowej",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "y_train_pred = pipeline.predict(X_train)\ny_test_pred = pipeline.predict(X_test)\nconfusion_matrix_test = confusion_matrix(y_train, y_train_pred)\nconfusion_matrix_train = confusion_matrix(y_test, y_test_pred)\nprint(\"Macierze pomyłek: \")\nprint(\"Zbiór uczący: \")\nprint(pd.DataFrame(confusion_matrix_test))\nprint(\"Zbiór testowy: \")\nprint(pd.DataFrame(confusion_matrix_train))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Wyznaczamy tp, tn, fp, fn",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "tn_train, fp_train, fn_train, tp_train = confusion_matrix_train.ravel()\ntn_test, fp_test, fn_test, tp_test = confusion_matrix_test.ravel()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Uzyskujemy czułość modelu",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sensitivity_train = tp_train/(tp_train + fn_train)\nsensitivity_test = tp_test/(tp_test + fn_test)\nprint(\"Czułość: \")\nprint(\"Zbiór uczący: \", sensitivity_train)\nprint(\"Zbiór testowy: \", sensitivity_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Uzyskujemy swoistość modelu",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"Swoistość: \")\nprint(\"Zbiór uczący: \", tn_train/(tn_train + fp_train))\nprint(\"Zbiór testowy: \", tn_test/(tn_test + fp_test))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Uzyskujemy precyzje modelu",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "precision_train = tp_train/(tp_train + fp_train)\nprecision_test = tp_test/(tp_test + fp_test)\nprint(\"Precyzja: \")\nprint(\"Zbiór uczący: \", precision_train)\nprint(\"Zbiór testowy: \", precision_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Uzyskujemy f1 modelu",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"F1: \")\nprint(\"Zbiór uczący: \", 2*sensitivity_train*precision_train/(sensitivity_train + precision_train))\nprint(\"Zbiór testowy: \", 2*sensitivity_test*precision_test/(sensitivity_test + precision_test))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Wyświetlenie wykresu ważności cech",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "importances = pipeline[\"las\"].feature_importances_\nplt.figure(figsize=(15,5))\nplt.barh(range(len(importances)), importances)\nplt.yticks(range(len(importances)), pipeline[\"prep\"].get_feature_names_out())\nplt.xlabel('Ważność cech')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Uzyskujemy krzywą roc wraz z auc dla zbioru uczącego",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "y_train_prob = pipeline.predict_proba(X_train)[:, 1]\nfpr, tpr, thresholds = roc_curve(y_train, y_train_prob, pos_label = 1)\nauc = roc_auc_score(y_train, y_train_prob)\nplt.figure(figsize=(8,8))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='AUC = %0.2f' % auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('1 - specyficzność')\nplt.ylabel('Czułość')\nplt.title('Krzywa ROC - zbiór uczący')\nplt.legend(loc=\"lower right\")\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Uzyskujemy krzywą roc wraz z auc dla zbioru testowego",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "y_test_prob = pipeline.predict_proba(X_test)[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, y_test_prob, pos_label = 1)\nauc = roc_auc_score(y_test, y_test_prob)\nplt.figure(figsize=(8,8))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='AUC = %0.2f' % auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('1 - specyficzność')\nplt.ylabel('Czułość')\nplt.title('Krzywa ROC - zbiór testowy')\nplt.legend(loc=\"lower right\")\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}